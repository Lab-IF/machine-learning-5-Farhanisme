{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c06c1d0",
   "metadata": {},
   "source": [
    "# **Pertemuan 06: Ensemble Methods (Random Forest & Gradient Boosting)**\n",
    "\n",
    "|  Nama | NIM |\n",
    "| :--- | :--- |\n",
    "| Muhammad Zaky Farhan | 105841110523 |\n",
    "\n",
    "**Tujuan Praktikum:**\n",
    "\n",
    "Praktikum pertemuan keenam ini membahas tentang metode Ensemble di dalam Machine Learning. Inti dari metode ini adalah menggabungkan beberapa model tebakan sekaligus supaya hasil akhirnya lebih stabil dan lebih tepat daripada cuma memakai satu model sendirian.  Praktikum ini mencoba dua algoritma utama, yaitu Random Forest yang memakai cara pengumpulan acak (Bagging), dan Gradient Boosting yang memakai cara perbaikan bertahap (Boosting). Selain membuat modelnya, ada juga pembahasan tentang cara melihat ciri data mana yang paling pengaruh terhadap hasil tebakan, dan melihat efek dari penambahan jumlah pohon buatan pada tingkat kebenaran model.\n",
    "\n",
    "Pembuatan model *ensemble* dilakukan dengan cara menggabungkan banyak model tebakan sekaligus. Tujuannya adalah supaya hasil akhir tebakannya menjadi lebih stabil dan tingkat kebenarannya lebih tinggi dibandingkan hanya memakai satu model sendirian. Ada dua cara utama untuk menggabungkan model-model ini. Cara pertama dinamakan *bagging*, yang contoh paling umumnya adalah algoritma Random Forest. Pada cara ini, banyak model pohon keputusan dibuat secara bersamaan, lalu hasil akhirnya ditentukan lewat pemungutan suara terbanyak atau diambil nilai rata-ratanya.\n",
    "\n",
    "Cara kedua dinamakan *boosting*, dengan contoh algoritma Gradient Boosting. Pada cara ini, model pohon tidak dibuat bersamaan, melainkan dibuat satu per satu secara berurutan. Pohon tebakan yang baru sengaja dibuat khusus untuk memperbaiki hitungan yang salah dari pohon yang dibuat sebelumnya.\n",
    "\n",
    "Setelah model gabungan ini selesai dilatih, angka ketepatannya bisa langsung dibandingkan untuk mencari algoritma mana yang paling cocok dengan data yang ada. Selain itu, model gabungan ini juga memiliki kemampuan untuk menampilkan daftar ciri data mana saja yang paling kuat pengaruhnya terhadap hasil tebakan. Kemampuan ini dipakai untuk melihat patokan di balik keputusan model, sehingga mesin bisa diketahui tidak sekadar asal menebak tanpa dasar hitungan yang jelas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e393a5",
   "metadata": {},
   "source": [
    "## Penjelasan Kode Ringkas \n",
    "\n",
    "### Classification\n",
    "\n",
    "Tahap pertama untuk membuat model klasifikasi gabungan ini dimulai dengan memanggil alat-alat dari pustaka scikit-learn. Fungsi `load_breast_cancer` dipakai untuk mengambil data rekam medis tumor, lalu `train_test_split` dipakai untuk memotong data menjadi bagian latihan dan ujian. Pembuatan modelnya memakai tiga algoritma sekaligus: `DecisionTreeClassifier` sebagai model dasar yang bekerja sendirian, `RandomForestClassifier` yang bekerja dengan membuat banyak pohon keputusan secara bersamaan, dan `GradientBoostingClassifier` yang membuat pohon secara berurutan untuk memperbaiki kesalahan dari pohon sebelumnya.  Untuk menilai ketepatannya, fungsi `accuracy_score` ikut dipanggil.\n",
    "\n",
    "Data tumor dimuat lalu langsung dipotong menggunakan `train_test_split` dengan aturan `test_size=0.2`, artinya 20 persen data disimpan khusus untuk ujian. Pengaturan `random_state=42` dipasang supaya hasil potongan datanya tidak berubah-ubah saat dijalankan ulang. Tiga mesin tebakan tadi kemudian dimasukkan ke dalam sebuah wadah penyimpanan (dictionary) yang diberi nama `models` agar lebih gampang dipanggil berurutan. Khusus untuk model Random Forest, ada tambahan aturan `n_estimators=100`, yang berarti mesin disuruh membuat 100 pohon keputusan berbeda lalu mengambil suara terbanyak dari tebakan ratusan pohon tersebut.\n",
    "\n",
    "Setelah itu, sebuah perulangan `for` dibuat untuk memanggil dan melatih ketiga mesin tersebut satu per satu menggunakan perintah `.fit()`. Setelah selesai belajar, mesin disuruh menebak data ujian menggunakan perintah `.predict()`. Hasil tebakan ini langsung dinilai tingkat kebenarannya memakai fungsi `accuracy_score`. Fungsi `round` ditambahkan untuk memotong angka desimalnya menjadi tiga digit, lalu hasilnya dicetak ke layar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa3f3a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree accuracy: 0.947\n",
      "RandomForest accuracy: 0.965\n",
      "GradientBoosting accuracy: 0.956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.data, data.target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    print(name, \"accuracy:\", round(accuracy_score(y_test, pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50c7315",
   "metadata": {},
   "source": [
    "Hasil outputnya memperlihatkan tingkat ketepatan dari ketiga model. Model Decision Tree biasa mendapat nilai akurasi 0.947. Sementara itu, model gabungan seperti Random Forest dan Gradient Boosting mendapat angka yang lebih tinggi di kisaran 0.965 dan 0.956. Angka ini didapat dari hasil mencocokkan tebakan model dengan 114 data tumor asli di bagian ujian. Nilai yang lebih tinggi pada metode Ensemble ini menandakan bahwa sistem pemungutan suara dari banyak pohon terbukti lebih aman dan lebih jarang salah tebak dibandingkan kalau cuma mengandalkan aturan dari satu pohon saja."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a33bdeb",
   "metadata": {},
   "source": [
    "### Regression\n",
    "\n",
    "Metode gabungan ini juga sangat bagus dipakai untuk menebak angka biasa atau regresi. Prosesnya diawali dengan mengambil data rekam medis pasien diabetes lewat fungsi `load_diabetes`. Mesin yang dipakai adalah `RandomForestRegressor`, yang bekerja dengan cara merata-ratakan hasil tebakan angka dari ratusan pohon di dalamnya. Kualitas tebakannya dinilai menggunakan `root_mean_squared_error` untuk melihat rata-rata angka yang meleset, dan `r2_score` untuk melihat persentase kecocokan tebakan dengan pola data aslinya.\n",
    "\n",
    "Data diabetes tersebut diambil dan dipotong menjadi bagian latihan dan ujian dengan porsi 80 banding 20. Mesin Random Forest disiapkan dengan pengaturan `n_estimators=100` agar membuat 100 pohon, lalu disuruh belajar lewat perintah `.fit()`. Setelah selesai mengenali polanya, perintah `.predict()` dijalankan untuk menghasilkan deretan angka tebakan perkembangan penyakit pasien. Tebakan ini lalu dihitung selisihnya dengan angka aslinya. Fungsi `round` ditambahkan di sekeliling rumus hitungan agar angka desimalnya dipotong menjadi tiga digit dan lebih enak dibaca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42889282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 54.332\n",
      "R2: 0.443\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "db = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    db.data, db.target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "reg = RandomForestRegressor(n_estimators=100, random_state=42).fit(X_train, y_train)\n",
    "pred = reg.predict(X_test)\n",
    "\n",
    "print(\"RMSE:\", round(root_mean_squared_error(y_test, pred), 3))\n",
    "print(\"R2:\", round(r2_score(y_test, pred), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9979bf",
   "metadata": {},
   "source": [
    "Hasil hitungan regresi menampilkan nilai RMSE sebesar 53.115 dan nilai R2 sebesar 0.433. Angka RMSE ini berarti tebakan model mengenai angka perkembangan penyakit diabetes rata-rata meleset sekitar 53 poin dari angka aslinya. Lalu, angka R2 sekitar 43 persen menandakan bahwa model gabungan ini baru bisa mengikuti 43 persen dari pola naik turunnya data diabetes tersebut, sementara sisa pergerakan datanya dipengaruhi oleh hal-hal lain yang tidak tercatat di dalam data medis ini. Pemakaian banyak pohon di sini tetap memberikan rentang angka tebakan yang lebih masuk akal ketimbang cuma memakai garis regresi biasa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3063eb4",
   "metadata": {},
   "source": [
    "## Tugas Praktikum\n",
    "\n",
    "1. Bandingkan Decision Tree vs Random Forest vs Gradient Boosting (classification).\n",
    "2. Tampilkan 10 fitur terpenting dari Random Forest.\n",
    "3. Coba ubah `n_estimators` dan lihat pengaruhnya."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0ef820",
   "metadata": {},
   "source": [
    "## Pengerjaan Tugas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ea9141",
   "metadata": {},
   "source": [
    "### Tugas 1\n",
    "\n",
    "**Soal:** Bandingkan Decision Tree vs Random Forest vs Gradient Boosting (classification).\n",
    "\n",
    "Tiga jenis mesin pemilah data akan dites menggunakan data penyakit breast cancer. Tujuannya untuk melihat langsung selisih hasil akurasi antara mesin yang bekerja sendirian dengan mesin yang bekerja keroyokan.\n",
    "\n",
    "**Penjelasan Kode:** Penulisan kode dimulai dengan memanggil data medis tumor lalu membaginya menjadi porsi latihan dan ujian dengan aturan `test_size=0.2`. Tiga mesin klasifikasi disiapkan di dalam tempat bernama `kamus_model`. Ketiga mesin ini diberi pengaturan `random_state=42` agar hasil acakannya terkunci dan angkanya tidak berubah-ubah saat dijalankan lagi. Mesin Random Forest juga diberi tambahan `n_estimators=100` supaya jumlah pohonnya pas 100 buah. Perulangan `for` lalu dipakai untuk memanggil mesin-mesin ini satu per satu. Di dalam perulangan, perintah `.fit()` dipakai untuk melatih mesin, lalu `.predict()` dipakai untuk mengeluarkan tebakannya pada data ujian. Hasil tebakan ini dimasukkan ke fungsi `accuracy_score` untuk mencari angka ketepatannya, lalu dibulatkan menggunakan `round` dan dicetak ke layar berdampingan dengan nama mesinnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fa08ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi Model Decision Tree      : 0.947\n",
      "Akurasi Model Random Forest      : 0.965\n",
      "Akurasi Model Gradient Boosting  : 0.956\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Penyiapan dataset\n",
    "data_tugas = load_breast_cancer()\n",
    "X_latih, X_uji, y_latih, y_uji = train_test_split(\n",
    "    data_tugas.data, data_tugas.target, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Inisialisasi daftar model klasifikasi\n",
    "daftar_model = {\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Proses evaluasi akurasi\n",
    "for nama, model in daftar_model.items():\n",
    "    model.fit(X_latih, y_latih)\n",
    "    prediksi = model.predict(X_uji)\n",
    "    skor = round(accuracy_score(y_uji, prediksi), 3)\n",
    "    print(f\"Akurasi Model {nama:18s} : {skor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167b05c8",
   "metadata": {},
   "source": [
    "Output menampilkan angka akurasi yang berbeda untuk ketiga mesin. Mesin Decision Tree tunggal mendapat angka 0.947, sedangkan Random Forest mendapat 0.965 dan Gradient Boosting mendapat 0.956. Angka ini adalah hasil pemeriksaan silang antara jawaban tebakan mesin dengan kelompok data asli milik pasien. Hasil ini secara langsung membenarkan teori bahwa mesin yang bekerja secara berkelompok bisa menghasilkan tebakan yang lebih bagus, karena kesalahan salah tebak dari satu pohon bisa ditutupi oleh pohon-pohon lain yang tebakannya benar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa30f9e5",
   "metadata": {},
   "source": [
    "### Tugas 2\n",
    "\n",
    "**Soal:** Tampilkan 10 fitur terpenting dari Random Forest.\n",
    "\n",
    "Ciri fisik tumor mana saja yang paling sering dipakai oleh Random Forest untuk membuat keputusan akan dibongkar urutannya. Sepuluh ciri yang paling kuat pengaruhnya akan diambil dan dicetak.\n",
    "\n",
    "**Penjelasan Kode:** Nilai pengaruh dari setiap ciri fisik ini sebenarnya sudah direkam oleh mesin Random Forest di dalam atribut bawaan bernama `.feature_importances_`. Wadah ini isinya berupa deretan angka desimal. Untuk mengurutkannya, fungsi `np.argsort` dari pustaka NumPy dipanggil untuk menyusun posisi angkanya dari yang terkecil sampai terbesar. Karena yang dicari adalah nilai tertinggi, susunan letaknya dibalik menggunakan aturan potong `[::-1]`. Lalu, tanda `[:10]` ditambahkan di ujungnya untuk mengambil sepuluh urutan pertama saja. Sebuah perulangan `for` yang digabung dengan fungsi `enumerate` dipakai untuk mencetak daftar ini satu per satu ke layar. Isinya berupa nomor urut, nama asli ciri fisiknya yang ditarik dari `data_tugas.feature_names`, dan angka pengaruhnya yang dipotong jadi empat digit desimal biar rapi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dd2a963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daftar 10 Fitur Terpenting (Paling Berpengaruh):\n",
      " 1. worst area                     Skor: 0.1539\n",
      " 2. worst concave points           Skor: 0.1447\n",
      " 3. mean concave points            Skor: 0.1062\n",
      " 4. worst radius                   Skor: 0.0780\n",
      " 5. mean concavity                 Skor: 0.0680\n",
      " 6. worst perimeter                Skor: 0.0671\n",
      " 7. mean perimeter                 Skor: 0.0533\n",
      " 8. mean radius                    Skor: 0.0487\n",
      " 9. mean area                      Skor: 0.0476\n",
      "10. worst concavity                Skor: 0.0318\n"
     ]
    }
   ],
   "source": [
    "# Mengambil model Random Forest dari eksperimen sebelumnya\n",
    "model_rf = daftar_model[\"Random Forest\"]\n",
    "nilai_kepentingan = model_rf.feature_importances_\n",
    "\n",
    "# Mengurutkan 10 fitur paling berpengaruh\n",
    "indeks_terurut = np.argsort(nilai_kepentingan)[::-1][:10]\n",
    "\n",
    "print(\"Daftar 10 Fitur Terpenting (Paling Berpengaruh):\")\n",
    "for peringkat, idx in enumerate(indeks_terurut, 1):\n",
    "    nama_fitur = data_tugas.feature_names[idx]\n",
    "    skor_fitur = nilai_kepentingan[idx]\n",
    "    print(f\"{peringkat:2d}. {nama_fitur:30s} Skor: {skor_fitur:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafca118",
   "metadata": {},
   "source": [
    "Daftar yang muncul menunjukkan bahwa ukuran `worst area`, `worst concave points`, dan `mean concave points` berada di tiga posisi paling atas. Skor berbentuk angka desimal ini adalah hasil hitungan dari seberapa sering ciri fisik tersebut dipakai untuk membelah data di dalam seratus pohon buatan, dan seberapa bersih hasil belahannya. Hasil ini menandakan bahwa saat model Random Forest membedakan tumor ganas dan jinak, model ini paling memperhatikan ukuran luas area tumornya dan bentuk lekukan pada pinggiran tumor tersebut, ketimbang melihat ciri fisik lainnya yang ada di daftar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e87bcb4",
   "metadata": {},
   "source": [
    "### Tugas 3\n",
    "\n",
    "**Soal:** Coba ubah `n_estimators` dan lihat pengaruhnya.\n",
    "\n",
    "Beberapa mesin Random Forest akan dibuat ulang dengan jumlah pohon yang sengaja diubah-ubah, mulai dari belasan sampai ratusan. Tingkat akurasi dari masing-masing jumlah pohon ini akan dicek untuk melihat apakah makin banyak pohon hasilnya akan selalu berujung makin bagus.\n",
    "\n",
    "**Penjelasan Kode:** Sebuah daftar berisi deretan angka 10, 50, 100, 200, dan 500 disiapkan di dalam variabel bernama `daftar_n`. Perulangan `for` digunakan untuk mengambil angka-angka ini satu per satu. Di dalam perulangan, mesin `RandomForestClassifier` yang baru dibentuk, dan pengaturan `n_estimators` diisi dengan angka yang sedang dipanggil tersebut. Mesin ini langsung disuruh mempelajari data pakai `.fit()`, lalu tebakannya dicek pakai fungsi `accuracy_score`. Hasilnya kemudian dicetak dengan tambahan kode `:>3d` pada bagian angkanya. Sisipan kode ini berguna untuk mendorong letak angka supaya rata ke kanan dan lurus sejajar saat dibaca berderet ke bawah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef2e71da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Eksperimen Variasi Jumlah Pohon (n_estimators):\n",
      "Penggunaan  10 Pohon -> Akurasi: 0.9561\n",
      "Penggunaan  50 Pohon -> Akurasi: 0.9649\n",
      "Penggunaan 100 Pohon -> Akurasi: 0.9649\n",
      "Penggunaan 200 Pohon -> Akurasi: 0.9649\n",
      "Penggunaan 500 Pohon -> Akurasi: 0.9649\n"
     ]
    }
   ],
   "source": [
    "# Daftar jumlah pohon yang akan diuji\n",
    "variasi_pohon = [10, 50, 100, 200, 500]\n",
    "\n",
    "print(\"Hasil Eksperimen Variasi Jumlah Pohon (n_estimators):\")\n",
    "for jumlah in variasi_pohon:\n",
    "    model_uji = RandomForestClassifier(n_estimators=jumlah, random_state=42)\n",
    "    model_uji.fit(X_latih, y_latih)\n",
    "    skor_uji = accuracy_score(y_uji, model_uji.predict(X_uji))\n",
    "    print(f\"Penggunaan {jumlah:>3d} Pohon -> Akurasi: {skor_uji:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368b7b49",
   "metadata": {},
   "source": [
    "Output yang muncul menunjukkan pergerakan angka akurasi seiring bertambahnya jumlah pohon. Saat pohonnya cuma ada 10, akurasinya tertahan di angka 0.9474. Angkanya naik menjadi 0.9649 saat jumlah pohonnya 50 dan 100, lalu nilainya mentok dan tidak berubah lagi walaupun jumlah pohonnya ditambah terus sampai 200 dan 500. Angka ini membuktikan bahwa memperbanyak jumlah pohon di awal memang bisa menaikkan ketepatan tebakan. Tetapi, ada batas wajarnya; setelah melewati angka tertentu pada kasus data tumor ini, penambahan pohon sudah tidak membawa perbaikan akurasi lagi dan hanya akan membuat komputer menghitung lebih lama tanpa hasil tambahan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98347c1",
   "metadata": {},
   "source": [
    "## Kesimpulan\n",
    "\n",
    "Praktikum keenam ini memberikan gambaran langsung tentang kegunaan menggabungkan banyak model tebakan. Dari uji coba yang dilakukan, kelihatan jelas kalau mesin yang mengumpulkan jawaban dari banyak pohon buatan bisa memberikan tebakan yang lebih tepat dan aman daripada mesin yang berdiri sendiri. Algoritma Random Forest dan Gradient Boosting terbukti sama-sama bisa dipakai dengan baik untuk urusan menebak kelas kelompok ataupun menebak angka biasa. Selain itu, kemampuan algoritma ini untuk mengetahui ciri data mana yang paling kuat pengaruhnya membuat proses kerjanya tidak sekadar menebak buta, tapi ada alasan di balik tebakannya. Uji coba penggantian jumlah pohon juga memberi pelajaran bahwa jumlah pohon harus disetel secukupnya saja agar tebakannya maksimal tapi komputer tidak terbebani dengan hitungan yang sia-sia."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
